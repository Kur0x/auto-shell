# ============================================
# LLM 配置
# ============================================

# 选择你的 LLM 提供商，取消注释相应的配置

# ----------------------------------------
# 选项 1: OpenAI API（默认）
# ----------------------------------------
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx
OPENAI_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-3.5-turbo

# ----------------------------------------
# 选项 2: Ollama（本地）
# ----------------------------------------
# 1. 安装 Ollama: https://ollama.ai
# 2. 下载模型: ollama pull qwen2.5:7b
# 3. 取消注释以下配置:
#
# OPENAI_API_KEY=ollama
# OPENAI_BASE_URL=http://localhost:11434/v1
# LLM_MODEL=qwen2.5:7b

# 推荐的 Ollama 模型:
# - qwen2.5:7b (中文优秀，推荐)
# - qwen2.5:14b (更强大，需要更多内存)
# - llama3.1:8b (英文优秀)
# - mistral:7b (速度快)

# ----------------------------------------
# 选项 3: 其他 OpenAI 兼容 API
# ----------------------------------------
# OPENAI_API_KEY=your_api_key
# OPENAI_BASE_URL=https://your-api-endpoint.com/v1
# LLM_MODEL=your-model-name

# ============================================
# 执行配置
# ============================================

# 最大重试次数（默认: 3）
MAX_RETRIES=3

# ============================================
# 系统信息收集配置
# ============================================

# 是否收集详细的系统信息（默认: true）
# 启用后会收集OS发行版、版本、包管理器等详细信息
COLLECT_DETAILED_INFO=true

# 系统信息缓存时间（秒，默认: 300）
# 避免频繁收集系统信息，提高性能
SYSTEM_INFO_CACHE_TTL=300

# SSH模式下信息收集超时时间（秒，默认: 10）
SSH_INFO_TIMEOUT=10

# ============================================
# 上下文文件配置
# ============================================

# 单个上下文文件最大大小（字节，默认: 1048576 = 1MB）
MAX_CONTEXT_FILE_SIZE=1048576

# 最多支持的上下文文件数量（默认: 5）
MAX_CONTEXT_FILES=5

# 上下文文件默认编码（默认: utf-8）
CONTEXT_FILE_ENCODING=utf-8
