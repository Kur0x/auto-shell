#!/usr/bin/env python3
"""
Ollama é›†æˆæµ‹è¯•è„šæœ¬

æµ‹è¯• AutoShell ä¸ Ollama çš„é›†æˆæ˜¯å¦æ­£å¸¸å·¥ä½œã€‚
"""

import os
import sys
from rich.console import Console
from rich.panel import Panel

console = Console()

def test_ollama_connection():
    """æµ‹è¯• Ollama è¿æ¥"""
    console.print(Panel.fit(
        "[bold blue]Ollama è¿æ¥æµ‹è¯•[/bold blue]",
        border_style="blue"
    ))
    
    try:
        import requests
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            console.print("[green]âœ“[/green] Ollama æœåŠ¡è¿è¡Œæ­£å¸¸")
            models = response.json().get("models", [])
            if models:
                console.print(f"[green]âœ“[/green] å·²å®‰è£… {len(models)} ä¸ªæ¨¡å‹:")
                for model in models:
                    console.print(f"  - {model['name']}")
            else:
                console.print("[yellow]âš [/yellow] æœªæ‰¾åˆ°å·²å®‰è£…çš„æ¨¡å‹")
                console.print("[dim]æç¤º: è¿è¡Œ 'ollama pull qwen2.5:7b' ä¸‹è½½æ¨¡å‹[/dim]")
            return True
        else:
            console.print(f"[red]âœ—[/red] Ollama æœåŠ¡å“åº”å¼‚å¸¸: {response.status_code}")
            return False
    except Exception as e:
        console.print(f"[red]âœ—[/red] æ— æ³•è¿æ¥åˆ° Ollama: {str(e)}")
        console.print("[dim]æç¤º: ç¡®ä¿ Ollama å·²å®‰è£…å¹¶è¿è¡Œ[/dim]")
        console.print("[dim]å®‰è£…: https://ollama.ai[/dim]")
        console.print("[dim]å¯åŠ¨: ollama serve[/dim]")
        return False

def test_config():
    """æµ‹è¯•é…ç½®"""
    console.print("\n")
    console.print(Panel.fit(
        "[bold blue]é…ç½®æµ‹è¯•[/bold blue]",
        border_style="blue"
    ))
    
    # è®¾ç½® Ollama é…ç½®
    os.environ["OPENAI_API_KEY"] = "ollama"
    os.environ["OPENAI_BASE_URL"] = "http://localhost:11434/v1"
    os.environ["LLM_MODEL"] = "qwen2.5:7b"
    
    try:
        from autoshell.config import Config
        Config.validate()
        
        if Config.is_ollama():
            console.print("[green]âœ“[/green] Ollama é…ç½®æ£€æµ‹æ­£ç¡®")
        else:
            console.print("[red]âœ—[/red] Ollama é…ç½®æ£€æµ‹å¤±è´¥")
            return False
        
        console.print(f"[green]âœ“[/green] API Base URL: {Config.OPENAI_BASE_URL}")
        console.print(f"[green]âœ“[/green] Model: {Config.LLM_MODEL}")
        return True
    except Exception as e:
        console.print(f"[red]âœ—[/red] é…ç½®éªŒè¯å¤±è´¥: {str(e)}")
        return False

def test_llm_client():
    """æµ‹è¯• LLM å®¢æˆ·ç«¯"""
    console.print("\n")
    console.print(Panel.fit(
        "[bold blue]LLM å®¢æˆ·ç«¯æµ‹è¯•[/bold blue]",
        border_style="blue"
    ))
    
    try:
        from autoshell.llm import LLMClient
        from autoshell.context import ContextManager
        
        client = LLMClient()
        
        if not client.is_ollama:
            console.print("[red]âœ—[/red] LLM å®¢æˆ·ç«¯æœªæ£€æµ‹åˆ° Ollama")
            return False
        
        console.print("[green]âœ“[/green] LLM å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        
        # æµ‹è¯•ç®€å•æŸ¥è¯¢
        console.print("\n[dim]æµ‹è¯•æŸ¥è¯¢: 'åˆ—å‡ºå½“å‰ç›®å½•çš„æ–‡ä»¶'[/dim]")
        context_str = ContextManager.get_context_string()
        
        plan = client.generate_plan(
            "åˆ—å‡ºå½“å‰ç›®å½•çš„æ–‡ä»¶",
            context_str
        )
        
        if "steps" in plan and len(plan["steps"]) > 0:
            console.print(f"[green]âœ“[/green] æˆåŠŸç”Ÿæˆè®¡åˆ’ï¼ŒåŒ…å« {len(plan['steps'])} ä¸ªæ­¥éª¤")
            console.print(f"[dim]æ€è·¯: {plan.get('thought', 'N/A')}[/dim]")
            for i, step in enumerate(plan["steps"], 1):
                console.print(f"[dim]  {i}. {step.get('description', 'N/A')}[/dim]")
            return True
        else:
            console.print("[red]âœ—[/red] ç”Ÿæˆçš„è®¡åˆ’æ ¼å¼ä¸æ­£ç¡®")
            return False
            
    except Exception as e:
        console.print(f"[red]âœ—[/red] LLM å®¢æˆ·ç«¯æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        console.print(f"[dim]{traceback.format_exc()}[/dim]")
        return False

def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    console.print(Panel.fit(
        "[bold cyan]AutoShell Ollama é›†æˆæµ‹è¯•[/bold cyan]\n"
        "æµ‹è¯• Ollama é›†æˆæ˜¯å¦æ­£å¸¸å·¥ä½œ",
        title="æµ‹è¯•å¥—ä»¶",
        border_style="cyan"
    ))
    
    results = []
    
    # æµ‹è¯• 1: Ollama è¿æ¥
    results.append(("Ollama è¿æ¥", test_ollama_connection()))
    
    # æµ‹è¯• 2: é…ç½®
    results.append(("é…ç½®éªŒè¯", test_config()))
    
    # æµ‹è¯• 3: LLM å®¢æˆ·ç«¯
    results.append(("LLM å®¢æˆ·ç«¯", test_llm_client()))
    
    # æ€»ç»“
    console.print("\n")
    console.print(Panel.fit(
        "[bold blue]æµ‹è¯•æ€»ç»“[/bold blue]",
        border_style="blue"
    ))
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for name, result in results:
        status = "[green]âœ“ é€šè¿‡[/green]" if result else "[red]âœ— å¤±è´¥[/red]"
        console.print(f"{status} - {name}")
    
    console.print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        console.print("\n[bold green]ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Ollama é›†æˆæ­£å¸¸å·¥ä½œã€‚[/bold green]")
        return 0
    else:
        console.print("\n[bold red]âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œ Ollama æœåŠ¡ã€‚[/bold red]")
        return 1

if __name__ == "__main__":
    sys.exit(main())
